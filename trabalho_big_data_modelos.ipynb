{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayHTML('<div style=\"text-align:center\"><img src =\"https://github.com/romulomadu/PEDS/blob/master/algebra/tarefas/logos.png?raw=true\" /></div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos Dados\n",
    "\n",
    "Os dados foram ingeridos no HDFS com o nome `Churn_Modelling.csv` e então são lidos pelo Spark no formato de `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/Churn_Modelling.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_ = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "#df_.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in df_.dtypes if t[1] == 'int']\n",
    "numeric_data = df_.select(numeric_features).toPandas()\n",
    "n = len(numeric_data.columns)\n",
    "df = df_.select(\n",
    " 'CreditScore',\n",
    " 'Geography',\n",
    " 'Gender',\n",
    " 'Age',\n",
    " 'Tenure',\n",
    " 'Balance',\n",
    " 'NumOfProducts',\n",
    " 'HasCrCard',\n",
    " 'IsActiveMember',\n",
    " 'EstimatedSalary',\n",
    " 'Exited')\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados\n",
    "\n",
    "Uma vez que os dados estão carregados no Spark, vamos utilizar seu poder de processamento distribuído para realizar operações no `DataFrame` para preparar os dados para a modelagem do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "O *Spark* permite utilizar o método `Pipeline` para encadear operações de transformação dos dados, para isso faz uso da estrutura de gráfico direcional acíclio (DAG), desta forma foi possível escalonar as seguintes transformações nos dados:\n",
    "\n",
    "* Conversão das variáveis categóricas (*Geography*) para variáveis dummy, utilizando o método `OneHotEncoder`\n",
    "* Formatação dos dados criando as colunas `features` e `label` para adequar o formato dos dados para usar ocmo entrada no *SparkML*\n",
    "\n",
    "A vantagem de se utilizar o `Pipeline` se deve a capacidade de reaproveitamento das mesmas transformações para novos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']#, 'Exited']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'Exited', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['CreditScore',\n",
    " 'Age',\n",
    " 'Tenure',\n",
    " 'Balance',\n",
    " 'NumOfProducts',\n",
    " 'EstimatedSalary']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['CreditScore',\n",
    " 'Geography',\n",
    " 'Gender',\n",
    " 'Age',\n",
    " 'Tenure',\n",
    " 'Balance',\n",
    " 'NumOfProducts',\n",
    " 'HasCrCard',\n",
    " 'IsActiveMember',\n",
    " 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout\n",
    "\n",
    "Uma boa prática na modelagem de problemas de aprendizado de máquina é separar o conjunto de dados em dados de treino, que serão utlizados pelo algoritmo para aprender, e dados de teste, que serão usados para avaliar a performance do modelo. Essa técnica é denominada *Holdout* e pode-se implementá-la no *Spark* utilizano o método `randomSplit` do  `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística\n",
    "\n",
    "A regressão logística é uma técnica de aprendizado supervisionado para classificação que consiste na minimização na seguinte função de custo\n",
    "\n",
    "$$J(w) = \\frac{1}{m}\\[ \\sum \\limits_{x=1}^{m} y^{(i)} \\log h_w (x^{(i)}) + (1-y^{(i)}) \\log(1-h_w (x^{(i)})) \\]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "import numpy as np\n",
    "beta = np.sort(lrModel.coefficients)\n",
    "plt.plot(beta)\n",
    "plt.ylabel('Beta Coefficients')\n",
    "#display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(train.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "trainingSummary = lrModel.summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "#display(plt.show())\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "#display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "#predictions.select('Age', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions.toPandas()\n",
    "y_pred = result.prediction\n",
    "y_test = result.label\n",
    "from sklearn.metrics import roc_auc_score, recall_score, classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "dtModel = dt.fit(train)\n",
    "predictions = dtModel.transform(test)\n",
    "#predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions.toPandas()\n",
    "y_pred = result.prediction\n",
    "y_test = result.label\n",
    "from sklearn.metrics import roc_auc_score, recall_score, classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "#predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions.toPandas()\n",
    "y_pred = result.prediction\n",
    "y_test = result.label\n",
    "from sklearn.metrics import roc_auc_score, recall_score, classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(train)\n",
    "predictions = gbtModel.transform(test)\n",
    "#predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions.toPandas()\n",
    "y_pred = result.prediction\n",
    "y_test = result.label\n",
    "from sklearn.metrics import roc_auc_score, recall_score, classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name='CustId_input', defaultValue='15634602', label='CustId')\n",
    "custid_input= int(getArgument(\"CustId_input\"))\n",
    "plt.clf()\n",
    "input_df = df_.filter('CustomerId == {}'.format(custid_input))\n",
    "input_df = input_df.drop('CustomerId', 'RowNumber', 'Surname')\n",
    "input_df = pipelineModel.transform(input_df)\n",
    "#selectedCols = ['label', 'features'] + cols\n",
    "#input_df2 = input_df.select(selectedCols)\n",
    "pred_input = rfModel.transform(input_df)\n",
    "prob_exit_input = round((pred_input.select('probability').toPandas()['probability'].loc[0][1])*100,2)\n",
    "strategy = int(prob_exit_input/20) + 1\n",
    "if strategy == 1:\n",
    "  message = 'Não oferecer taxas diferenciadas'\n",
    "elif strategy > 1:\n",
    "  message = 'Ofereça taxas diferenciadas de nível {}'.format(strategy)\n",
    "\n",
    "displayHTML(\"\"\"<center><h1>O cliente tem {}% de chances de sair do Banco</h1>\n",
    "            <h3>{}</h3>\n",
    "            </center>\n",
    "            \"\"\".format(prob_exit_input, message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "name": "trabalho_big_data_modelos",
  "notebookId": 2229361034690802
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
